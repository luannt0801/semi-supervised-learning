{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\2024\\FIL 2024\\luan\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import liblary\n",
    "import torch\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from src.data import get_datasetCML, data_semi_learning\n",
    "from src.logging_config import logger\n",
    "from src.model.model import (\n",
    "    LSTMModel,\n",
    "    LeNet,\n",
    "    LeNet_5,\n",
    "    resnet20,\n",
    "    resnet32,\n",
    "    resnet44,\n",
    "    resnet56,\n",
    "    resnet110,\n",
    "    resnet1202,\n",
    ")\n",
    "from src.utils import *\n",
    "\n",
    "MODEL_DICT = {\n",
    "    \"LSTMModel\": LSTMModel,\n",
    "    \"LeNet\": LeNet,\n",
    "    \"LeNet_5\": LeNet_5,\n",
    "    \"resnet20\": resnet20,\n",
    "    \"resnet32\": resnet32,\n",
    "    \"resnet44\": resnet44,\n",
    "    \"resnet56\": resnet56,\n",
    "    \"resnet110\": resnet110,\n",
    "    \"resnet1202\": resnet1202,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Data\n",
    "1. First train model with 5 classes of Data (Cifar10)\n",
    "epoch [1, 5, 10, 20, 40, 50] --> acc increase\n",
    "--> Save model parameter \n",
    "\n",
    "2. Visualized\n",
    "Data with class (5 + n) collect outputs and visulized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run = \"LeNet_5\"\n",
    "data_use = \"cifar10\"\n",
    "num_classes = 10\n",
    "batch_size = 64\n",
    "learning_rate = 1e-5\n",
    "labeled_classed = [0,1,2,3,4]\n",
    "epochs = 50\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
    "##\n",
    "select_model = [0, 4, 9, 19, 39, 49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "check check the batch: tensor([[[-2.4291, -2.4291, -2.4291,  ...,  1.6030,  1.6612, -2.4291],\n",
      "         [ 1.5642,  1.0021,  0.9439,  ...,  1.6224,  1.1571, -2.4291],\n",
      "         [ 1.6999,  1.6805,  1.6224,  ...,  1.5061,  1.0214, -2.4291],\n",
      "         ...,\n",
      "         [-2.4291,  0.5368,  1.5642,  ...,  2.0101,  1.6612,  2.0101],\n",
      "         [-2.4291,  0.4399,  1.0214,  ...,  1.5061,  1.1571,  1.3316],\n",
      "         [-2.4291,  0.3817,  0.4205,  ..., -2.4291, -2.4291, -2.4291]],\n",
      "\n",
      "        [[-2.4183, -2.4183, -2.4183,  ...,  1.6724,  1.7314, -2.4183],\n",
      "         [ 1.6331,  1.0628,  1.0038,  ...,  1.6921,  1.2201, -2.4183],\n",
      "         [ 1.7708,  1.7511,  1.6921,  ...,  1.5741,  1.0824, -2.4183],\n",
      "         ...,\n",
      "         [-2.4183,  0.5908,  1.6331,  ...,  2.0855,  1.7314,  2.0855],\n",
      "         [-2.4183,  0.4924,  1.0824,  ...,  1.5741,  1.2201,  1.3971],\n",
      "         [-2.4183,  0.4334,  0.4728,  ..., -2.4183, -2.4183, -2.4183]],\n",
      "\n",
      "        [[-2.2214, -2.2214, -2.2214,  ...,  1.8367,  1.8953, -2.2214],\n",
      "         [ 1.7977,  1.2319,  1.1734,  ...,  1.8563,  1.3880, -2.2214],\n",
      "         [ 1.9343,  1.9148,  1.8563,  ...,  1.7392,  1.2514, -2.2214],\n",
      "         ...,\n",
      "         [-2.2214,  0.7637,  1.7977,  ...,  2.2465,  1.8953,  2.2465],\n",
      "         [-2.2214,  0.6661,  1.2514,  ...,  1.7392,  1.3880,  1.5636],\n",
      "         [-2.2214,  0.6076,  0.6466,  ..., -2.2214, -2.2214, -2.2214]]]):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trainning model with 5 classes [0,1,2,3,4]\n",
    "trainset_5class, trainset_unlabeled = data_semi_learning(data_use=data_use, num_class=num_classes, batch_size=64, labeled_classes=labeled_classed)\n",
    "\n",
    "for batch in trainset_5class:\n",
    "    print(f\"check check the batch: {batch[0]}:\\n\")\n",
    "    # print(f\"check check the idx: {idx}\")\n",
    "    # print(f\"check check the idx: {data}\")\n",
    "    break\n",
    "\n",
    "# for batch in trainset_unlabeled:\n",
    "#     print(f\"check check the batch: {batch[0]}:\\n\")\n",
    "#     # print(f\"check check the idx: {idx}\")\n",
    "#     # print(f\"check check the idx: {data}\")\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 391/391 [00:17<00:00, 22.81it/s]\n",
      "\u001b[1;36;48mEpoch [1] | Loss: 2.1336 | Accuracy: 23.70% \n",
      " (3329526526.py:30)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at model_save/LeNet_5_0.pth\n"
     ]
    }
   ],
   "source": [
    "trainloader5classes = DataLoader(trainset_5class, batch_size=64, shuffle=True)\n",
    "\n",
    "## trainning\n",
    "def train_one_epoch(model, trainloader, optimizer, criterion, device, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    progress_bar = tqdm(trainloader, desc=f\"Epoch {epoch+1}\", leave=True)\n",
    "\n",
    "    for idx, (inputs, labels) in enumerate(progress_bar):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    logger.info(f\"Epoch [{epoch+1}] | Loss: {epoch_loss:.4f} | Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "def trainning_main():\n",
    "    model_cls= MODEL_DICT.get(model_run, None)\n",
    "    model = model_cls(num_classes=num_classes).to(device)\n",
    "    \n",
    "    trainloader = trainloader5classes\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_one_epoch(model, trainloader, optimizer, criterion, device, epoch)\n",
    "        if epoch in [0, 4, 9, 19, 39, 49]:\n",
    "            torch.save(model.state_dict(), f\"model_save/{model_run}_{data_use}_{epoch}.pth\")\n",
    "            print(f\"Model saved at model_save/{model_run}_{epoch}.pth\")\n",
    "    \n",
    "\n",
    "trainning_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found .pth files: ['LeNet_cifar10_0.pth', 'LeNet_cifar10_19.pth', 'LeNet_cifar10_39.pth', 'LeNet_cifar10_4.pth', 'LeNet_cifar10_49.pth', 'LeNet_cifar10_9.pth']\n",
      "Loaded model type: <class 'collections.OrderedDict'>\n",
      "OrderedDict({'features.0.weight': tensor([[[[ 1.0764e-01, -9.7127e-02,  7.0996e-02, -7.3853e-02, -1.0007e-01],\n",
      "          [-5.2506e-02,  2.1857e-02, -3.0240e-02, -8.3655e-02, -1.0853e-01],\n",
      "          [-4.8249e-02, -1.0234e-01,  6.6734e-02, -1.0387e-01, -1.9594e-03],\n",
      "          [-1.1889e-01, -5.0460e-03,  4.1202e-02, -5.6854e-02, -8.6374e-02],\n",
      "          [-1.8547e-02, -8.9800e-02,  5.4877e-02,  3.4855e-02, -7.0144e-02]],\n",
      "\n",
      "         [[-7.4720e-02, -1.0311e-01, -7.5854e-02,  1.4496e-04, -4.5453e-02],\n",
      "          [ 1.2385e-02, -1.1012e-01,  7.4974e-02, -2.4934e-02, -3.8505e-02],\n",
      "          [-1.3797e-02,  4.5269e-02,  1.6125e-03, -4.9393e-02, -4.7396e-02],\n",
      "          [-2.4497e-02, -3.5167e-02,  4.1500e-02,  1.5700e-02, -7.6236e-02],\n",
      "          [ 6.3691e-02,  1.8406e-02,  7.6503e-02, -8.7787e-02,  8.0803e-02]],\n",
      "\n",
      "         [[-2.6001e-02,  8.0758e-02,  3.3529e-02, -1.4600e-02, -8.6683e-02],\n",
      "          [ 1.0783e-01,  1.0600e-01,  8.6275e-02,  3.9049e-02, -8.7719e-02],\n",
      "          [-7.7527e-02,  3.3981e-02, -1.1084e-01, -4.7105e-02, -8.1516e-02],\n",
      "          [ 5.5232e-02,  2.1512e-02, -4.3625e-02, -4.1173e-02, -4.8551e-02],\n",
      "          [-3.0293e-02,  7.9850e-02, -2.6313e-02, -8.9916e-03, -2.4540e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1848e-02, -2.8098e-03,  3.8302e-02, -2.5874e-03,  4.8808e-02],\n",
      "          [ 5.4219e-02,  7.1228e-02, -2.0792e-02,  7.2853e-02, -9.0515e-02],\n",
      "          [ 4.6632e-02, -2.4790e-02, -7.4173e-02,  4.5494e-02,  2.5784e-02],\n",
      "          [ 1.6488e-02,  6.5420e-02,  7.4950e-02,  1.0389e-01, -4.6209e-02],\n",
      "          [-5.7204e-03,  5.4402e-02,  2.5150e-02, -2.4636e-02,  1.0685e-01]],\n",
      "\n",
      "         [[ 3.4661e-02,  8.6409e-02, -6.8970e-02, -9.3829e-02,  5.8164e-02],\n",
      "          [ 1.0991e-01,  1.1630e-01, -9.8616e-02,  4.1494e-02, -9.2386e-02],\n",
      "          [ 1.0445e-01, -5.6264e-02,  8.9511e-02,  2.1822e-02, -9.8952e-02],\n",
      "          [-4.6135e-03, -3.5265e-03,  9.9987e-02, -9.3737e-02, -9.5807e-02],\n",
      "          [-5.3653e-02, -3.2377e-02,  8.6441e-02, -5.4950e-02, -3.0206e-02]],\n",
      "\n",
      "         [[-2.2323e-02, -6.8151e-02,  6.2511e-02,  6.5661e-02,  1.1513e-01],\n",
      "          [ 8.6461e-02, -8.2314e-02,  6.7317e-03, -5.5205e-02,  1.7438e-02],\n",
      "          [ 1.0658e-01,  8.9958e-02,  1.5897e-02,  2.9952e-02, -2.2161e-02],\n",
      "          [-1.3399e-03,  1.0584e-01,  9.2081e-02, -1.1745e-02,  3.8236e-02],\n",
      "          [ 1.2100e-01, -1.4640e-02, -7.9354e-02, -6.4200e-02,  3.2260e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9981e-02,  6.2764e-03, -2.8123e-02, -4.8235e-05,  1.1485e-02],\n",
      "          [ 3.3004e-02,  9.1831e-02,  7.2892e-02, -9.2504e-02,  1.0041e-01],\n",
      "          [-4.8185e-02, -9.5612e-02,  1.0165e-03,  1.0919e-03, -6.0360e-02],\n",
      "          [ 1.5557e-02, -2.8654e-02,  1.6149e-03, -6.1254e-02, -1.0463e-01],\n",
      "          [ 5.9060e-02, -3.1702e-02, -3.5063e-02,  3.4732e-02, -5.9985e-02]],\n",
      "\n",
      "         [[-1.0914e-01, -9.2698e-03,  1.0794e-01,  1.0119e-01,  1.1967e-01],\n",
      "          [ 6.7687e-02,  3.7394e-02, -6.3759e-02, -4.9120e-02,  1.0209e-01],\n",
      "          [-1.0649e-01,  1.2227e-02, -7.3694e-02, -8.1653e-02,  1.9199e-02],\n",
      "          [ 5.6709e-02,  2.1415e-02,  9.6291e-02, -8.9614e-02, -2.2482e-02],\n",
      "          [ 2.5713e-02, -8.7447e-02,  7.9557e-02, -2.9698e-02,  4.9978e-02]],\n",
      "\n",
      "         [[-5.6993e-02,  6.0356e-02,  7.0797e-03, -4.9998e-03,  2.2174e-02],\n",
      "          [ 8.4199e-03, -5.6751e-02, -3.4828e-02, -3.8418e-02, -4.3793e-02],\n",
      "          [ 7.2414e-02,  9.8900e-03,  4.3472e-02, -4.4064e-02, -1.0417e-01],\n",
      "          [ 2.5290e-02,  4.1340e-02, -4.3182e-02, -1.1028e-03, -9.9081e-02],\n",
      "          [-1.3063e-02, -5.1990e-02, -3.3030e-02,  6.4114e-02,  3.3854e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.1786e-02,  5.5872e-04,  1.0411e-01, -9.7645e-02, -3.7006e-02],\n",
      "          [-1.0617e-01,  4.0756e-02,  2.2235e-02,  8.2137e-02,  5.7262e-02],\n",
      "          [-1.1603e-01,  6.4933e-02, -5.8446e-02, -8.5542e-02,  4.5931e-02],\n",
      "          [ 4.4156e-03,  2.3700e-03, -5.9937e-02, -9.5761e-02, -2.4917e-02],\n",
      "          [ 4.7873e-02,  6.0691e-02,  6.0606e-03,  6.2321e-02, -2.3672e-02]],\n",
      "\n",
      "         [[-6.5448e-02, -2.9599e-02,  1.6040e-02,  6.3400e-02, -2.5285e-02],\n",
      "          [-1.1649e-02, -3.4780e-03,  2.3820e-02,  3.7192e-02, -1.0131e-01],\n",
      "          [-2.6809e-03, -8.7359e-02,  6.1114e-02,  7.4773e-02,  1.8888e-02],\n",
      "          [ 4.7451e-02, -1.4355e-02,  3.5380e-02, -1.0875e-01, -4.9188e-02],\n",
      "          [ 1.1181e-01, -4.1044e-02,  2.1954e-02, -8.7119e-02, -4.2819e-02]],\n",
      "\n",
      "         [[-3.8965e-02,  7.7780e-02, -3.5356e-02,  1.0696e-01,  3.7629e-02],\n",
      "          [ 2.4974e-02, -3.8725e-02,  7.9698e-02, -8.7521e-02, -4.7394e-02],\n",
      "          [-1.7386e-02, -5.1015e-02, -3.6460e-02, -1.7353e-02, -7.5126e-02],\n",
      "          [-2.4214e-03, -4.0335e-02, -5.9168e-02,  2.3344e-02,  2.4594e-02],\n",
      "          [ 2.5614e-03, -4.8068e-02,  3.1702e-03, -1.0808e-01,  1.7580e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.3972e-02,  4.0336e-02, -1.1562e-01,  3.8621e-02, -2.2820e-03],\n",
      "          [ 1.0362e-01, -8.6915e-02,  1.4948e-02,  1.5659e-02, -2.5586e-02],\n",
      "          [-8.0863e-02, -5.3315e-02, -1.0504e-01,  2.4623e-02,  2.6483e-02],\n",
      "          [ 4.4272e-02, -4.8197e-02,  8.2146e-02, -1.0122e-01, -2.6861e-02],\n",
      "          [-1.7531e-02, -3.7885e-02, -6.4246e-02, -9.5785e-02,  5.4392e-02]],\n",
      "\n",
      "         [[ 2.3073e-02, -1.7538e-02,  8.1201e-02,  6.0310e-03,  6.3138e-02],\n",
      "          [-8.8683e-02, -7.7046e-02,  3.8522e-02,  5.2679e-02, -8.7817e-02],\n",
      "          [ 2.9418e-02, -6.7567e-02, -3.3193e-02, -8.0445e-02, -5.2798e-02],\n",
      "          [ 1.7397e-02, -2.4643e-02,  1.0953e-01,  9.4529e-03, -5.8409e-02],\n",
      "          [-1.0654e-01,  2.4304e-03, -1.0312e-01, -1.0629e-01,  7.9666e-02]],\n",
      "\n",
      "         [[-4.8392e-02,  9.5271e-02, -8.4301e-02, -3.7244e-02,  6.6485e-02],\n",
      "          [ 9.2502e-02, -1.0440e-01, -2.3935e-02,  7.8863e-02,  5.2575e-02],\n",
      "          [ 7.9880e-03, -2.9299e-02,  1.2704e-02, -5.9003e-04, -6.9403e-02],\n",
      "          [-4.8698e-02, -2.2083e-02, -1.1599e-01,  2.4701e-02,  4.6862e-02],\n",
      "          [-1.0110e-01, -8.7688e-03,  3.2697e-03,  7.0381e-02,  5.0556e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.6529e-02, -1.0130e-01, -6.5229e-02,  5.3681e-02, -4.8174e-02],\n",
      "          [-6.5716e-02,  1.0752e-01,  1.1030e-02, -3.8103e-02,  6.1361e-02],\n",
      "          [ 1.7752e-02, -1.2524e-02,  1.1249e-02,  6.2025e-02, -3.1390e-02],\n",
      "          [-1.2303e-02, -7.8376e-02,  8.0547e-02,  3.3955e-02, -7.9882e-02],\n",
      "          [ 2.9619e-02,  4.4229e-02,  7.0670e-02, -4.1045e-02,  5.2394e-02]],\n",
      "\n",
      "         [[-1.0948e-01,  5.9692e-02, -1.3412e-02, -8.8055e-02,  6.5077e-03],\n",
      "          [-1.0650e-03, -6.0047e-02,  1.0870e-02, -1.0749e-01,  5.3200e-02],\n",
      "          [ 8.2856e-02,  6.1046e-02, -4.7102e-03, -8.2700e-02, -4.4964e-02],\n",
      "          [ 1.6610e-02,  1.0002e-01,  5.1874e-03,  6.6674e-02,  1.1380e-01],\n",
      "          [ 7.5838e-02,  1.0453e-01,  8.3700e-02, -7.0377e-02, -1.0131e-01]],\n",
      "\n",
      "         [[ 2.2710e-02,  5.6602e-02,  3.8254e-02,  1.1450e-01,  3.1558e-02],\n",
      "          [ 7.0083e-02,  8.1646e-02,  9.2209e-02, -4.6798e-02,  5.2187e-02],\n",
      "          [ 7.3465e-02,  5.4881e-02, -7.7945e-02,  6.1955e-02, -6.6857e-02],\n",
      "          [ 8.2040e-02,  6.5062e-02,  4.5862e-02, -6.7943e-02,  4.8653e-02],\n",
      "          [-7.6256e-02, -1.6904e-02,  7.9105e-02,  6.5622e-02,  8.2974e-04]]]],\n",
      "       device='cuda:0'), 'features.0.bias': tensor([-0.1060, -0.0591, -0.0642,  0.1170,  0.1179, -0.0517], device='cuda:0'), 'features.3.weight': tensor([[[[-0.0562, -0.0003, -0.0717,  0.0613,  0.0050],\n",
      "          [ 0.0348,  0.0476,  0.0511,  0.0222, -0.0012],\n",
      "          [-0.0375, -0.0278, -0.0133,  0.0089, -0.0038],\n",
      "          [ 0.0754, -0.0327,  0.0343,  0.0684, -0.0176],\n",
      "          [ 0.0022, -0.0744, -0.0347,  0.0825,  0.0395]],\n",
      "\n",
      "         [[-0.0585,  0.0643,  0.0174, -0.0116, -0.0754],\n",
      "          [ 0.0608, -0.0147, -0.0667,  0.0614, -0.0401],\n",
      "          [-0.0498, -0.0664,  0.0835, -0.0397, -0.0685],\n",
      "          [-0.0754, -0.0122, -0.0338, -0.0326,  0.0813],\n",
      "          [ 0.0197, -0.0254, -0.0683,  0.0048,  0.0384]],\n",
      "\n",
      "         [[ 0.0364, -0.0234, -0.0026, -0.0755, -0.0638],\n",
      "          [ 0.0362, -0.0676,  0.0699, -0.0353,  0.0024],\n",
      "          [-0.0273, -0.0758, -0.0026, -0.0802,  0.0176],\n",
      "          [-0.0044, -0.0770,  0.0368, -0.0367, -0.0346],\n",
      "          [-0.0277, -0.0329,  0.0587, -0.0482, -0.0588]],\n",
      "\n",
      "         [[-0.0617, -0.0691, -0.0181, -0.0060,  0.0490],\n",
      "          [-0.0707, -0.0706, -0.0006, -0.0305, -0.0332],\n",
      "          [ 0.0556,  0.0548,  0.0567, -0.0178, -0.0781],\n",
      "          [-0.0557,  0.0597, -0.0709,  0.0401, -0.0490],\n",
      "          [ 0.0675,  0.0262, -0.0708, -0.0181,  0.0088]],\n",
      "\n",
      "         [[-0.0765, -0.0441, -0.0157,  0.0426,  0.0533],\n",
      "          [ 0.0657,  0.0515, -0.0035, -0.0188,  0.0117],\n",
      "          [-0.0577, -0.0308,  0.0255,  0.0362, -0.0667],\n",
      "          [-0.0722,  0.0531, -0.0327, -0.0161,  0.0718],\n",
      "          [ 0.0190,  0.0776, -0.0619, -0.0058,  0.0768]],\n",
      "\n",
      "         [[ 0.0554,  0.0113,  0.0454,  0.0248,  0.0262],\n",
      "          [-0.0597, -0.0635,  0.0083,  0.0506,  0.0510],\n",
      "          [ 0.0573, -0.0131,  0.0162,  0.0313,  0.0841],\n",
      "          [ 0.0436, -0.0560,  0.0418,  0.0675,  0.0622],\n",
      "          [ 0.0569, -0.0493, -0.0032,  0.0338, -0.0195]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0793,  0.0841, -0.0728,  0.0343, -0.0300],\n",
      "          [-0.0104, -0.0423, -0.0043, -0.0023, -0.0563],\n",
      "          [-0.0584,  0.0570, -0.0067, -0.0266, -0.0157],\n",
      "          [-0.0288,  0.0013,  0.0634, -0.0177, -0.0560],\n",
      "          [-0.0498,  0.0313,  0.0394,  0.0593,  0.0294]],\n",
      "\n",
      "         [[ 0.0073, -0.0551,  0.0813, -0.0692, -0.0163],\n",
      "          [ 0.0770, -0.0617,  0.0034,  0.0149, -0.0185],\n",
      "          [-0.0123,  0.0499,  0.0491, -0.0236, -0.0122],\n",
      "          [-0.0196, -0.0397,  0.0509,  0.0377,  0.0449],\n",
      "          [ 0.0479, -0.0456,  0.0801, -0.0164,  0.0191]],\n",
      "\n",
      "         [[-0.0278,  0.0426,  0.0292,  0.0183,  0.0850],\n",
      "          [ 0.0066, -0.0694,  0.0353, -0.0253,  0.0534],\n",
      "          [ 0.0830, -0.0412, -0.0707,  0.0554,  0.0175],\n",
      "          [-0.0692,  0.0712,  0.0448,  0.0227, -0.0685],\n",
      "          [ 0.0203, -0.0187, -0.0640,  0.0700, -0.0084]],\n",
      "\n",
      "         [[-0.0089,  0.0522,  0.0526,  0.0644,  0.0465],\n",
      "          [ 0.0374, -0.0469,  0.0825, -0.0416,  0.0821],\n",
      "          [-0.0713,  0.0838, -0.0359, -0.0313,  0.0530],\n",
      "          [ 0.0036, -0.0137, -0.0684, -0.0086,  0.0028],\n",
      "          [-0.0057, -0.0416,  0.0018,  0.0583,  0.0039]],\n",
      "\n",
      "         [[ 0.0298, -0.0304, -0.0191, -0.0110, -0.0188],\n",
      "          [-0.0621,  0.0397,  0.0378,  0.0303, -0.0751],\n",
      "          [-0.0107,  0.0704, -0.0583, -0.0359, -0.0527],\n",
      "          [-0.0582,  0.0482, -0.0268,  0.0404, -0.0353],\n",
      "          [-0.0750, -0.0417,  0.0194, -0.0645,  0.0505]],\n",
      "\n",
      "         [[-0.0769, -0.0164, -0.0455, -0.0142,  0.0077],\n",
      "          [-0.0316, -0.0548,  0.0216, -0.0556, -0.0063],\n",
      "          [-0.0283,  0.0554,  0.0118,  0.0301,  0.0235],\n",
      "          [ 0.0723,  0.0616, -0.0302, -0.0486,  0.0680],\n",
      "          [ 0.0532,  0.0233, -0.0397, -0.0714,  0.0449]]],\n",
      "\n",
      "\n",
      "        [[[-0.0278,  0.0640, -0.0586, -0.0180,  0.0819],\n",
      "          [-0.0174, -0.0135, -0.0466,  0.0502, -0.0288],\n",
      "          [-0.0497, -0.0468, -0.0454, -0.0361,  0.0713],\n",
      "          [-0.0311,  0.0474, -0.0492,  0.0767,  0.0044],\n",
      "          [-0.0722,  0.0009, -0.0080, -0.0043,  0.0560]],\n",
      "\n",
      "         [[ 0.0838, -0.0497,  0.0553,  0.0099, -0.0507],\n",
      "          [-0.0084,  0.0830,  0.0600,  0.0638, -0.0567],\n",
      "          [ 0.0430,  0.0405, -0.0659,  0.0042, -0.0395],\n",
      "          [-0.0252, -0.0555, -0.0380,  0.0390,  0.0198],\n",
      "          [ 0.0187, -0.0322,  0.0839, -0.0588, -0.0116]],\n",
      "\n",
      "         [[ 0.0073, -0.0148, -0.0309,  0.0830,  0.0031],\n",
      "          [ 0.0644, -0.0106, -0.0155, -0.0116,  0.0249],\n",
      "          [ 0.0640,  0.0701, -0.0268, -0.0219, -0.0465],\n",
      "          [-0.0591,  0.0309,  0.0424, -0.0224, -0.0551],\n",
      "          [ 0.0534,  0.0356, -0.0549,  0.0380,  0.0831]],\n",
      "\n",
      "         [[-0.0712,  0.0218,  0.0453, -0.0530, -0.0231],\n",
      "          [-0.0753,  0.0329,  0.0406,  0.0167, -0.0355],\n",
      "          [-0.0714,  0.0288,  0.0823, -0.0042,  0.0523],\n",
      "          [ 0.0471,  0.0598,  0.0322, -0.0452,  0.0325],\n",
      "          [ 0.0581,  0.0368, -0.0510,  0.0505,  0.0289]],\n",
      "\n",
      "         [[ 0.0272,  0.0772,  0.0583, -0.0711,  0.0511],\n",
      "          [-0.0441, -0.0648, -0.0082, -0.0087, -0.0386],\n",
      "          [ 0.0488, -0.0370,  0.0481,  0.0432, -0.0388],\n",
      "          [-0.0712,  0.0208, -0.0351,  0.0194, -0.0106],\n",
      "          [-0.0541,  0.0161, -0.0728, -0.0276, -0.0518]],\n",
      "\n",
      "         [[-0.0493,  0.0760,  0.0389,  0.0767,  0.0746],\n",
      "          [ 0.0104,  0.0595, -0.0639,  0.0480, -0.0506],\n",
      "          [-0.0499,  0.0688, -0.0575,  0.0769,  0.0100],\n",
      "          [ 0.0576,  0.0836, -0.0458,  0.0229, -0.0426],\n",
      "          [ 0.0440,  0.0683,  0.0094, -0.0223,  0.0629]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0233,  0.0816,  0.0717, -0.0635, -0.0498],\n",
      "          [ 0.0491,  0.0287,  0.0198,  0.0086, -0.0251],\n",
      "          [ 0.0612, -0.0667,  0.0710, -0.0665, -0.0631],\n",
      "          [-0.0158, -0.0538,  0.0499, -0.0709, -0.0418],\n",
      "          [-0.0334,  0.0789,  0.0306,  0.0049,  0.0172]],\n",
      "\n",
      "         [[ 0.0345,  0.0361, -0.0494,  0.0127,  0.0415],\n",
      "          [ 0.0166, -0.0609, -0.0731, -0.0202, -0.0745],\n",
      "          [ 0.0366, -0.0333,  0.0812,  0.0319, -0.0676],\n",
      "          [ 0.0432,  0.0765,  0.0422,  0.0843,  0.0232],\n",
      "          [-0.0288, -0.0583, -0.0107, -0.0300,  0.0340]],\n",
      "\n",
      "         [[-0.0412, -0.0758,  0.0128,  0.0247,  0.0544],\n",
      "          [-0.0681,  0.0834,  0.0577, -0.0048,  0.0828],\n",
      "          [ 0.0751, -0.0433, -0.0493, -0.0346,  0.0542],\n",
      "          [-0.0702,  0.0498, -0.0418, -0.0187, -0.0009],\n",
      "          [-0.0608, -0.0395, -0.0574, -0.0748, -0.0292]],\n",
      "\n",
      "         [[ 0.0775, -0.0068,  0.0082, -0.0713,  0.0252],\n",
      "          [-0.0114, -0.0550, -0.0055, -0.0448,  0.0032],\n",
      "          [ 0.0423,  0.0735, -0.0559, -0.0075,  0.0374],\n",
      "          [ 0.0462, -0.0252, -0.0540, -0.0263,  0.0369],\n",
      "          [ 0.0403, -0.0385,  0.0381,  0.0665,  0.0795]],\n",
      "\n",
      "         [[ 0.0245, -0.0054,  0.0096, -0.0478, -0.0162],\n",
      "          [ 0.0272, -0.0530,  0.0178,  0.0518, -0.0620],\n",
      "          [-0.0641,  0.0774, -0.0772,  0.0660, -0.0280],\n",
      "          [-0.0274,  0.0597, -0.0617,  0.0021,  0.0437],\n",
      "          [ 0.0048,  0.0413, -0.0657,  0.0200,  0.0625]],\n",
      "\n",
      "         [[ 0.0068, -0.0344, -0.0396, -0.0226,  0.0533],\n",
      "          [ 0.0405, -0.0671,  0.0381,  0.0018, -0.0142],\n",
      "          [ 0.0479,  0.0014,  0.0735,  0.0006,  0.0633],\n",
      "          [-0.0752,  0.0554,  0.0207, -0.0361,  0.0031],\n",
      "          [ 0.0747, -0.0409,  0.0153,  0.0812, -0.0236]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0310, -0.0279,  0.0282,  0.0058, -0.0423],\n",
      "          [ 0.0079, -0.0362,  0.0146,  0.0737,  0.0014],\n",
      "          [ 0.0564,  0.0233, -0.0192,  0.0692,  0.0252],\n",
      "          [ 0.0634, -0.0274,  0.0801,  0.0338, -0.0387],\n",
      "          [-0.0482, -0.0077, -0.0360, -0.0607, -0.0115]],\n",
      "\n",
      "         [[-0.0480, -0.0054,  0.0270,  0.0024,  0.0808],\n",
      "          [ 0.0630,  0.0844,  0.0719, -0.0763, -0.0046],\n",
      "          [ 0.0445, -0.0685,  0.0606, -0.0343, -0.0712],\n",
      "          [ 0.0269, -0.0554,  0.0664, -0.0719,  0.0712],\n",
      "          [ 0.0003,  0.0330,  0.0617,  0.0777, -0.0510]],\n",
      "\n",
      "         [[-0.0345, -0.0009,  0.0441, -0.0456,  0.0582],\n",
      "          [-0.0230,  0.0831, -0.0410, -0.0138,  0.0701],\n",
      "          [-0.0694, -0.0243, -0.0740, -0.0424,  0.0630],\n",
      "          [-0.0176, -0.0279, -0.0630, -0.0537,  0.0068],\n",
      "          [ 0.0765,  0.0693, -0.0654,  0.0165,  0.0625]],\n",
      "\n",
      "         [[ 0.0637, -0.0705, -0.0017, -0.0520, -0.0322],\n",
      "          [-0.0457,  0.0712, -0.0680,  0.0220,  0.0184],\n",
      "          [ 0.0213, -0.0285, -0.0276, -0.0033, -0.0642],\n",
      "          [-0.0684,  0.0774,  0.0468,  0.0535,  0.0654],\n",
      "          [-0.0547, -0.0124, -0.0600, -0.0496,  0.0586]],\n",
      "\n",
      "         [[ 0.0773,  0.0601,  0.0408,  0.0211,  0.0478],\n",
      "          [-0.0473,  0.0657, -0.0071, -0.0666, -0.0177],\n",
      "          [ 0.0297,  0.0419, -0.0232,  0.0034,  0.0481],\n",
      "          [ 0.0213,  0.0375,  0.0028, -0.0442,  0.0730],\n",
      "          [-0.0124,  0.0695,  0.0486,  0.0624, -0.0043]],\n",
      "\n",
      "         [[ 0.0230,  0.0323,  0.0240,  0.0681,  0.0529],\n",
      "          [ 0.0124,  0.0458, -0.0527,  0.0362,  0.0030],\n",
      "          [ 0.0414,  0.0655,  0.0619,  0.0334, -0.0295],\n",
      "          [ 0.0093, -0.0251,  0.0719,  0.0626,  0.0256],\n",
      "          [ 0.0773,  0.0195, -0.0358,  0.0632,  0.0151]]],\n",
      "\n",
      "\n",
      "        [[[-0.0375, -0.0499, -0.0758, -0.0238, -0.0417],\n",
      "          [ 0.0678, -0.0154, -0.0270,  0.0269, -0.0609],\n",
      "          [ 0.0657, -0.0699,  0.0602, -0.0422, -0.0258],\n",
      "          [-0.0226, -0.0627,  0.0795,  0.0743, -0.0263],\n",
      "          [-0.0232,  0.0276,  0.0653,  0.0831,  0.0165]],\n",
      "\n",
      "         [[-0.0197, -0.0560,  0.0387,  0.0292,  0.0091],\n",
      "          [-0.0101,  0.0377,  0.0512,  0.0659, -0.0700],\n",
      "          [ 0.0272,  0.0229,  0.0775,  0.0683,  0.0403],\n",
      "          [-0.0707,  0.0521, -0.0590,  0.0049, -0.0231],\n",
      "          [ 0.0705,  0.0152,  0.0387,  0.0333, -0.0490]],\n",
      "\n",
      "         [[ 0.0501, -0.0202, -0.0225, -0.0051,  0.0583],\n",
      "          [ 0.0308,  0.0450,  0.0245,  0.0299,  0.0028],\n",
      "          [ 0.0191,  0.0822, -0.0637,  0.0750, -0.0317],\n",
      "          [-0.0281, -0.0746,  0.0538,  0.0233,  0.0763],\n",
      "          [-0.0200, -0.0043,  0.0491, -0.0635, -0.0596]],\n",
      "\n",
      "         [[-0.0303, -0.0708, -0.0755,  0.0090,  0.0322],\n",
      "          [ 0.0669, -0.0766,  0.0089, -0.0171, -0.0120],\n",
      "          [ 0.0809, -0.0621,  0.0314, -0.0190, -0.0404],\n",
      "          [-0.0341,  0.0014, -0.0359,  0.0296, -0.0160],\n",
      "          [ 0.0059, -0.0053,  0.0659,  0.0590,  0.0709]],\n",
      "\n",
      "         [[ 0.0756,  0.0642,  0.0071,  0.0682,  0.0757],\n",
      "          [-0.0518,  0.0049,  0.0199, -0.0463,  0.0206],\n",
      "          [ 0.0488,  0.0040, -0.0759, -0.0304,  0.0761],\n",
      "          [ 0.0170,  0.0263, -0.0658, -0.0152, -0.0392],\n",
      "          [ 0.0293,  0.0562,  0.0309,  0.0803,  0.0629]],\n",
      "\n",
      "         [[ 0.0478,  0.0799,  0.0289, -0.0625, -0.0671],\n",
      "          [-0.0112, -0.0157, -0.0153,  0.0107, -0.0169],\n",
      "          [ 0.0445, -0.0164, -0.0056,  0.0106, -0.0250],\n",
      "          [ 0.0650, -0.0600, -0.0512, -0.0073,  0.0184],\n",
      "          [ 0.0242, -0.0636,  0.0159,  0.0061, -0.0453]]]], device='cuda:0'), 'features.3.bias': tensor([ 0.0065,  0.0359, -0.0708,  0.0772, -0.0037,  0.0396,  0.0688, -0.0344,\n",
      "        -0.0337,  0.0830, -0.0336, -0.0736, -0.0248,  0.0635,  0.0369, -0.0219],\n",
      "       device='cuda:0'), 'classifier.0.weight': tensor([[-0.0142, -0.0015, -0.0265,  ...,  0.0037, -0.0118, -0.0188],\n",
      "        [-0.0073, -0.0189,  0.0184,  ..., -0.0466,  0.0289, -0.0357],\n",
      "        [ 0.0315,  0.0116,  0.0249,  ...,  0.0475,  0.0397,  0.0451],\n",
      "        ...,\n",
      "        [ 0.0225,  0.0203, -0.0137,  ...,  0.0323, -0.0149,  0.0497],\n",
      "        [-0.0270, -0.0025,  0.0489,  ...,  0.0381, -0.0356, -0.0255],\n",
      "        [-0.0412,  0.0175, -0.0243,  ..., -0.0338,  0.0236,  0.0517]],\n",
      "       device='cuda:0'), 'classifier.0.bias': tensor([ 0.0175,  0.0002, -0.0364, -0.0283,  0.0534,  0.0059, -0.0271,  0.0155,\n",
      "         0.0189,  0.0277,  0.0340,  0.0194,  0.0208, -0.0147, -0.0085, -0.0022,\n",
      "        -0.0007,  0.0192,  0.0077,  0.0472, -0.0028,  0.0134, -0.0285, -0.0242,\n",
      "        -0.0093,  0.0174, -0.0109, -0.0457,  0.0179,  0.0461,  0.0314, -0.0458,\n",
      "        -0.0131,  0.0252,  0.0099,  0.0485,  0.0499, -0.0091,  0.0087,  0.0438,\n",
      "        -0.0369, -0.0019,  0.0449, -0.0230, -0.0096,  0.0310, -0.0438,  0.0182,\n",
      "         0.0241, -0.0125, -0.0255,  0.0136, -0.0051, -0.0370, -0.0452,  0.0315,\n",
      "         0.0335, -0.0038, -0.0346, -0.0295,  0.0401,  0.0056, -0.0001,  0.0156,\n",
      "        -0.0359, -0.0467, -0.0168,  0.0360, -0.0133,  0.0412,  0.0262,  0.0048,\n",
      "        -0.0316,  0.0141,  0.0463,  0.0316,  0.0185, -0.0229, -0.0214, -0.0525,\n",
      "         0.0070,  0.0144, -0.0444, -0.0295, -0.0124,  0.0067,  0.0083,  0.0080,\n",
      "         0.0243, -0.0389,  0.0233, -0.0301,  0.0547,  0.0124,  0.0421,  0.0440,\n",
      "        -0.0466, -0.0074,  0.0331, -0.0100,  0.0239,  0.0188, -0.0443, -0.0430,\n",
      "         0.0468,  0.0313, -0.0005, -0.0005, -0.0321, -0.0146,  0.0049, -0.0040,\n",
      "         0.0407, -0.0041, -0.0416,  0.0144,  0.0110,  0.0262,  0.0109, -0.0262],\n",
      "       device='cuda:0'), 'classifier.2.weight': tensor([[-0.0223,  0.0581,  0.0375,  ..., -0.0438, -0.0309, -0.0735],\n",
      "        [-0.0141, -0.0534, -0.0006,  ..., -0.0636, -0.0491,  0.0301],\n",
      "        [ 0.0122,  0.0887, -0.0808,  ..., -0.0830,  0.0044,  0.0590],\n",
      "        ...,\n",
      "        [-0.0693,  0.0104, -0.0212,  ..., -0.0565,  0.0894, -0.0283],\n",
      "        [-0.0048,  0.0062, -0.0842,  ...,  0.0638, -0.0553, -0.0397],\n",
      "        [-0.0424,  0.0878, -0.0723,  ..., -0.0511,  0.0716,  0.0272]],\n",
      "       device='cuda:0'), 'classifier.2.bias': tensor([-0.0572,  0.0637, -0.0695,  0.0083,  0.0717, -0.0051,  0.0308,  0.0829,\n",
      "         0.0711, -0.0654,  0.0096,  0.0308, -0.0821,  0.0104, -0.0374,  0.0157,\n",
      "         0.0236, -0.0273, -0.0315, -0.0774, -0.0622,  0.0678,  0.0925,  0.0288,\n",
      "         0.0462, -0.0632,  0.0872,  0.0002, -0.0234,  0.0845,  0.0180, -0.0484,\n",
      "        -0.0055, -0.0238,  0.0151,  0.0711, -0.0820, -0.0521,  0.0345, -0.0890,\n",
      "         0.0581,  0.0227,  0.0274, -0.0143,  0.0155,  0.0653, -0.0570,  0.0436,\n",
      "         0.0370,  0.0219,  0.0857, -0.0705,  0.0139, -0.0772, -0.0654,  0.0684,\n",
      "         0.0089,  0.0235,  0.0446, -0.0355, -0.0275, -0.0256, -0.0531, -0.0277,\n",
      "        -0.0885,  0.0648, -0.0786,  0.0805, -0.0445,  0.0412,  0.0003, -0.0619,\n",
      "         0.0586, -0.0886,  0.0252,  0.0176,  0.0134,  0.0811, -0.0385,  0.0182,\n",
      "        -0.0868,  0.0189,  0.0148,  0.0691], device='cuda:0'), 'classifier.4.weight': tensor([[-8.6856e-02, -6.3686e-02,  7.4031e-02,  6.7978e-02,  5.1175e-02,\n",
      "         -7.3509e-02, -5.2778e-02,  2.3553e-03,  3.5196e-02,  6.8362e-02,\n",
      "          4.3775e-02,  3.4376e-03, -7.5812e-02,  6.8750e-02,  3.2872e-02,\n",
      "         -4.6000e-02, -7.8858e-02, -4.2607e-02, -8.3393e-03,  1.0099e-01,\n",
      "         -7.0817e-02,  7.8471e-02,  6.6079e-02, -5.7746e-02,  9.9298e-02,\n",
      "         -1.8522e-02,  5.6748e-02,  2.9855e-02,  5.4501e-02, -1.1166e-02,\n",
      "          5.8639e-02, -1.0068e-01,  1.0841e-02,  3.4831e-02,  2.2013e-02,\n",
      "         -5.0640e-03,  1.0239e-01,  9.5673e-03, -4.6669e-02, -9.1676e-02,\n",
      "          6.7929e-02,  5.7448e-02, -4.0431e-03,  2.2949e-02, -2.5383e-02,\n",
      "          6.1875e-02, -1.0098e-01,  7.6621e-02,  7.4384e-02,  1.0255e-01,\n",
      "          1.7098e-02, -3.6524e-02,  7.0918e-02,  1.0370e-01, -4.9536e-02,\n",
      "          8.2524e-02, -4.7070e-02,  3.4337e-02,  5.8423e-02, -2.9836e-02,\n",
      "         -5.4491e-02, -7.2384e-02,  6.4163e-02,  2.8542e-02,  2.6603e-02,\n",
      "          3.7581e-02, -6.6126e-02,  7.1798e-02,  1.0820e-01,  1.3169e-02,\n",
      "         -1.8105e-02,  3.2880e-03,  4.3491e-03,  1.1082e-01,  7.1517e-02,\n",
      "         -5.2356e-02,  1.3385e-02,  1.4363e-02,  2.1371e-02, -7.2348e-02,\n",
      "         -4.2487e-02, -5.9004e-02,  8.1587e-02,  6.9410e-02],\n",
      "        [-7.9714e-02,  4.1173e-02,  7.7658e-02, -1.7064e-02, -5.3759e-02,\n",
      "          1.0116e-01, -4.6913e-02, -1.0113e-01,  1.1615e-02,  1.1472e-02,\n",
      "         -8.0572e-03, -5.7641e-02,  8.2963e-03, -1.9564e-02,  7.6405e-02,\n",
      "         -7.9247e-02,  5.3919e-02, -2.6149e-02,  6.9307e-02, -3.2768e-03,\n",
      "          9.6489e-02,  2.1283e-02, -9.5017e-02,  6.7495e-02, -5.5414e-02,\n",
      "          3.2199e-02,  2.1290e-02,  6.5512e-02, -6.4778e-02, -1.3304e-02,\n",
      "         -5.3143e-02, -2.6735e-02,  1.0930e-02, -6.7683e-02, -1.8473e-02,\n",
      "          8.8194e-02, -1.4806e-02,  6.0654e-02,  7.3403e-02,  1.2865e-02,\n",
      "         -4.6802e-02, -5.3023e-02,  9.5382e-02, -7.7474e-02,  7.9753e-02,\n",
      "          1.5600e-02,  3.8919e-02,  1.1195e-01,  7.0082e-02,  4.5100e-02,\n",
      "         -1.4404e-02,  7.4344e-04,  1.0778e-02, -7.9448e-02,  7.7972e-02,\n",
      "          8.7794e-02,  1.0369e-01, -4.8850e-02, -2.0878e-02, -3.2975e-02,\n",
      "          1.0521e-01, -1.9141e-02, -7.6080e-02, -1.9224e-02, -7.4033e-02,\n",
      "          1.6997e-02,  8.6686e-02, -8.8807e-02,  6.9022e-02, -3.2548e-03,\n",
      "          5.7949e-02,  3.9374e-02,  1.4795e-02, -5.1068e-02,  1.4283e-02,\n",
      "          4.6064e-02, -5.1797e-02, -2.3879e-02,  8.4023e-02,  1.0949e-01,\n",
      "         -6.2857e-04, -4.9102e-02,  2.9172e-02,  8.1756e-02],\n",
      "        [-1.9221e-02, -1.4873e-02, -3.1958e-02,  4.9588e-02,  5.2611e-02,\n",
      "          3.0195e-02,  5.1996e-02, -1.4876e-02,  1.0352e-02, -2.1017e-02,\n",
      "         -1.6166e-02,  1.1520e-02, -7.0823e-02, -2.2712e-02, -4.2795e-03,\n",
      "         -5.8402e-02,  1.1802e-02,  8.4329e-02,  4.4051e-02,  5.4553e-02,\n",
      "         -4.8646e-02, -9.1306e-02,  8.5624e-02, -3.4982e-02,  1.2065e-02,\n",
      "         -9.8194e-02,  6.2224e-02, -9.8239e-02, -9.1426e-02,  7.7644e-02,\n",
      "         -8.9144e-02,  1.0634e-01,  3.1294e-02,  8.4622e-02,  3.0798e-02,\n",
      "         -6.6255e-02, -2.0445e-03,  3.8077e-02,  1.0664e-02,  2.0598e-02,\n",
      "          1.0741e-01, -1.8991e-02,  6.5001e-02,  5.0927e-02,  9.8113e-02,\n",
      "          6.2082e-02, -9.3072e-02, -7.3778e-02, -4.2708e-02, -9.2609e-02,\n",
      "         -6.2636e-02, -4.0351e-02, -4.7105e-02, -7.9896e-02, -5.0349e-02,\n",
      "         -1.2060e-02,  7.3820e-02,  1.5661e-02,  3.4206e-02, -1.7493e-02,\n",
      "          1.0881e-02,  5.2741e-02, -9.0550e-02, -7.6286e-02, -8.6468e-02,\n",
      "         -9.6480e-02,  9.6395e-02,  7.4621e-02,  5.7245e-02,  5.9697e-03,\n",
      "          1.0226e-01, -6.4915e-02,  9.1871e-03, -3.7966e-03, -6.5303e-02,\n",
      "          1.7230e-02,  4.1682e-02, -1.0205e-01, -1.0725e-01,  9.6127e-02,\n",
      "         -8.5183e-02, -1.0125e-01,  5.9690e-02, -6.8421e-02],\n",
      "        [-1.5375e-02, -9.2996e-02,  7.8104e-02,  1.4385e-02, -4.0540e-02,\n",
      "          8.9049e-02,  8.4210e-03, -2.2295e-02,  8.3072e-02,  3.8707e-02,\n",
      "          5.7120e-02, -3.1225e-02,  3.4965e-02,  4.0336e-03, -2.0813e-02,\n",
      "         -1.4701e-02, -6.7855e-02, -3.9522e-02,  5.7718e-02, -6.3166e-02,\n",
      "         -8.2294e-02, -1.1830e-02, -2.1242e-02,  2.4590e-02, -5.0227e-02,\n",
      "          6.8806e-02,  3.2146e-02, -3.5305e-02,  4.5663e-02, -5.3048e-02,\n",
      "         -9.9309e-02,  1.0455e-01,  1.3605e-02,  9.4371e-02,  1.0825e-01,\n",
      "          6.6931e-02, -5.5035e-02, -3.8663e-02,  8.1532e-02, -1.7000e-02,\n",
      "          1.8759e-02, -4.5474e-02,  9.1299e-02,  4.0722e-02, -3.4066e-02,\n",
      "         -5.4690e-02,  8.3211e-02, -4.4018e-03, -5.1390e-02, -3.8729e-02,\n",
      "         -5.2428e-02, -8.0289e-02,  8.9241e-02,  4.9579e-02,  1.0544e-01,\n",
      "          6.7617e-02,  9.0596e-02,  3.8900e-02, -4.2695e-02, -5.0199e-02,\n",
      "         -3.5647e-02, -8.3490e-02, -5.3499e-02,  2.6945e-02,  9.3379e-03,\n",
      "         -9.0080e-02, -5.3005e-02,  8.9151e-02, -1.0062e-01,  8.2076e-02,\n",
      "          7.9640e-02,  4.1543e-02, -4.6327e-02, -4.6192e-02, -1.8517e-03,\n",
      "         -1.0670e-02,  9.9047e-02,  6.4662e-03,  9.7026e-02,  2.9364e-02,\n",
      "         -6.0377e-02,  1.0549e-01, -2.4331e-02,  2.6366e-02],\n",
      "        [ 7.6587e-02,  2.9997e-03,  4.8495e-02,  5.9887e-02, -9.5831e-02,\n",
      "          7.2725e-03,  1.0130e-01,  7.2227e-02, -8.0883e-03,  2.4128e-03,\n",
      "          3.0571e-02,  2.7913e-02,  9.5952e-03, -4.7328e-02, -8.6314e-02,\n",
      "         -6.7293e-02, -4.0290e-03, -9.0139e-02,  2.9094e-02,  9.8028e-02,\n",
      "         -5.3190e-02,  9.3078e-02,  7.8106e-02, -7.9818e-02, -1.1937e-02,\n",
      "          3.5560e-02,  1.1132e-01, -7.5863e-02,  7.6355e-02,  6.4029e-02,\n",
      "         -7.9830e-02, -8.1289e-02,  6.8041e-02, -4.7534e-02, -6.2501e-02,\n",
      "          6.4062e-02,  1.6828e-02,  6.2555e-02, -2.5338e-03, -6.3051e-02,\n",
      "         -5.9796e-03,  2.4149e-02,  7.6553e-03,  2.8708e-02,  4.5741e-02,\n",
      "         -8.0124e-03,  2.2711e-02,  6.6652e-02, -9.1094e-03, -2.3841e-02,\n",
      "         -5.2933e-02,  6.5779e-02, -2.8243e-02, -8.0837e-02,  1.9172e-02,\n",
      "         -4.8896e-02,  9.9967e-02, -3.1727e-02, -1.1994e-03,  9.6038e-02,\n",
      "          1.1279e-01, -1.4522e-02, -9.3566e-02, -2.8332e-02,  1.9798e-02,\n",
      "         -4.6808e-02,  3.7692e-02, -5.6189e-02, -3.1229e-02,  5.8364e-02,\n",
      "          1.0868e-01, -5.5666e-03,  3.6321e-02, -4.7561e-02, -1.0302e-01,\n",
      "          3.8300e-03, -3.1262e-02,  5.6984e-02,  6.2498e-02, -5.2066e-02,\n",
      "         -4.7473e-02,  1.0836e-01, -5.8230e-02,  8.4571e-02],\n",
      "        [-1.1319e-01,  5.3434e-02,  5.0321e-02, -9.1911e-02, -6.0058e-02,\n",
      "         -5.4375e-02,  2.8754e-02,  2.6435e-02,  6.8310e-02,  7.1751e-02,\n",
      "         -8.9605e-02, -8.3839e-02, -7.1728e-02,  7.0998e-02, -7.5165e-02,\n",
      "         -5.1884e-03, -8.5467e-02,  7.5643e-02,  1.0576e-01,  7.0467e-02,\n",
      "          4.8962e-02, -6.5958e-02, -1.1003e-01,  2.8992e-02,  9.7724e-02,\n",
      "          5.7312e-02, -1.1597e-02, -1.0833e-01, -1.6465e-02, -4.7325e-02,\n",
      "          1.0524e-01,  7.6272e-02, -4.9896e-02,  3.3276e-02, -1.0295e-01,\n",
      "         -2.2307e-02,  1.3616e-02,  3.5028e-02, -1.0298e-01, -1.5297e-03,\n",
      "          2.6993e-02,  5.4033e-02,  1.9371e-02, -3.9789e-02,  5.1622e-02,\n",
      "         -9.7094e-02,  9.4274e-02, -3.8422e-02, -8.5385e-02,  5.1888e-02,\n",
      "         -6.9973e-03, -9.9393e-02, -3.8037e-02,  6.5639e-03,  2.5164e-03,\n",
      "         -6.1439e-02,  2.6116e-02, -7.4082e-02,  5.5562e-02, -4.2447e-02,\n",
      "          3.5483e-02,  9.4465e-02,  2.7403e-02, -6.7283e-02,  9.5904e-02,\n",
      "         -1.0546e-01,  6.7302e-02, -4.2174e-02, -2.7453e-02,  6.0151e-02,\n",
      "          9.4199e-02,  9.0919e-02, -1.0354e-01, -3.7417e-02,  8.6962e-02,\n",
      "          6.7309e-02,  5.7859e-02, -9.8667e-02, -3.2336e-02, -1.0931e-01,\n",
      "         -9.4426e-02, -6.3267e-02, -1.0623e-01,  1.0334e-01],\n",
      "        [ 1.5979e-02,  5.0896e-02,  6.5997e-02, -6.5473e-03, -4.4325e-02,\n",
      "         -5.4880e-02, -1.8597e-02,  4.6696e-02,  5.7800e-02,  1.0504e-01,\n",
      "          8.3207e-02, -2.5278e-03, -7.6945e-02, -9.7992e-02,  5.3795e-02,\n",
      "          4.4909e-02, -8.0281e-03, -2.3232e-02, -2.3530e-02,  7.9223e-02,\n",
      "         -1.9815e-02,  6.3995e-03, -7.1065e-03,  2.2531e-02,  1.5878e-02,\n",
      "          4.5103e-02,  4.1828e-02,  4.0656e-02,  9.9779e-02,  6.9682e-02,\n",
      "         -5.6813e-02, -9.5407e-02, -1.0835e-01, -4.6926e-04, -7.0337e-02,\n",
      "         -9.6872e-03, -3.7911e-02,  5.3792e-02, -8.9987e-02,  5.5555e-02,\n",
      "         -6.2339e-02,  1.1190e-02,  8.8693e-02,  3.5473e-02, -1.9638e-02,\n",
      "          3.3048e-03,  2.6021e-02, -3.1320e-03, -5.3649e-02, -6.6316e-02,\n",
      "         -1.0012e-01,  6.4631e-02, -7.7717e-02, -7.5378e-02,  3.1899e-02,\n",
      "         -3.9463e-02,  8.3801e-02, -7.5645e-02, -1.0773e-01,  1.8372e-02,\n",
      "         -1.0431e-01, -5.3177e-02, -3.8929e-02, -8.6386e-02,  3.4815e-02,\n",
      "          9.9437e-02,  3.3092e-02, -2.5350e-02,  9.4562e-02,  6.0083e-02,\n",
      "         -9.4320e-02,  1.3763e-02,  2.8097e-02,  5.9035e-02, -7.1295e-02,\n",
      "          2.9442e-02, -7.9437e-02,  6.5756e-02,  8.3603e-02,  3.2563e-02,\n",
      "         -1.1141e-01, -5.6425e-02,  1.8358e-02,  1.5835e-02],\n",
      "        [-3.0316e-02, -1.1814e-03,  8.6469e-02,  6.2561e-02, -9.1977e-02,\n",
      "          5.5691e-02, -1.0670e-01,  6.0611e-02,  3.2393e-03, -8.4453e-02,\n",
      "         -3.8263e-02,  4.8949e-02,  1.7743e-02,  3.1322e-02,  5.1372e-02,\n",
      "         -1.0330e-01, -1.0268e-01,  9.1786e-02,  3.5329e-02, -1.5786e-02,\n",
      "          6.5762e-02, -4.6095e-02, -3.2876e-02,  5.0837e-02,  6.5344e-02,\n",
      "          5.0905e-02, -3.9636e-03, -3.3526e-02,  3.5460e-02,  1.6661e-02,\n",
      "         -2.9960e-02, -3.1607e-02, -1.0006e-01, -7.6956e-02,  1.5464e-02,\n",
      "         -9.4413e-02, -9.8433e-02, -7.3503e-02, -5.0861e-03, -2.2471e-02,\n",
      "         -1.6958e-02, -5.1694e-02, -5.8943e-02, -1.0058e-01,  2.4587e-02,\n",
      "         -3.1220e-03, -1.1645e-02,  1.3472e-02, -2.6835e-02, -3.3520e-02,\n",
      "         -5.8166e-03,  3.5702e-02, -8.9344e-02, -2.2086e-02,  4.6113e-02,\n",
      "          3.6664e-02,  5.9970e-02,  4.3343e-02, -3.0044e-02,  3.2734e-03,\n",
      "          7.2489e-02, -9.2358e-02,  1.1909e-02,  2.4079e-02, -7.5177e-03,\n",
      "         -6.0741e-02, -5.7777e-02, -3.5213e-02, -4.1277e-02, -8.1933e-03,\n",
      "         -9.2898e-02,  1.7431e-02, -1.6355e-02, -1.9101e-02,  6.9572e-02,\n",
      "         -2.4489e-02, -1.0818e-01,  1.4608e-02, -6.2607e-02,  8.0606e-02,\n",
      "         -1.0870e-01, -5.4420e-02, -9.3759e-02,  8.6577e-02],\n",
      "        [-5.2045e-02, -3.8129e-02,  3.4891e-02, -6.8764e-03, -3.9798e-02,\n",
      "         -4.3134e-02,  1.9992e-02,  5.0318e-02, -2.1802e-03,  1.2351e-02,\n",
      "         -1.1142e-01, -3.9310e-02, -3.8267e-02, -9.7668e-02, -7.4864e-02,\n",
      "          1.0282e-02, -5.7903e-02, -1.1352e-02, -6.6191e-02, -4.6547e-02,\n",
      "         -4.6716e-02,  8.9343e-02,  7.6758e-02, -6.9716e-02,  7.8508e-02,\n",
      "          1.3685e-02,  2.5177e-02,  9.3412e-02,  1.0295e-01, -8.8151e-03,\n",
      "         -7.3211e-03, -1.4571e-02, -1.7839e-02,  1.0036e-01, -6.5113e-02,\n",
      "          9.5675e-02, -9.3858e-02, -9.1720e-02, -6.9453e-02,  8.1855e-02,\n",
      "         -8.7080e-02,  6.1113e-02,  8.5029e-02, -5.9794e-02,  1.1308e-04,\n",
      "         -4.3216e-02, -7.0227e-02, -3.5234e-02,  6.9338e-02,  5.7405e-03,\n",
      "         -1.0361e-01, -5.5236e-02,  8.0172e-02,  9.7387e-02,  7.9801e-02,\n",
      "         -9.6828e-02,  7.4881e-02,  7.7110e-02,  9.7399e-02, -4.3023e-02,\n",
      "          3.5973e-02, -1.4654e-03,  1.0175e-01,  4.9571e-02,  2.2468e-02,\n",
      "          3.4840e-02,  1.0056e-01, -2.2950e-02,  9.2169e-02,  2.6095e-02,\n",
      "          4.0716e-02, -6.8898e-02, -1.1115e-01, -4.8060e-02, -8.7244e-02,\n",
      "         -2.3595e-02,  8.9332e-02, -1.1340e-01,  2.3594e-02,  9.9159e-02,\n",
      "          4.4081e-02, -3.4110e-02, -9.1951e-02,  1.9291e-02],\n",
      "        [ 2.7957e-05, -3.3104e-02, -7.1644e-02, -1.5718e-02,  3.6790e-02,\n",
      "         -8.3835e-03, -5.3952e-02, -1.0472e-01, -2.4877e-02,  8.2900e-02,\n",
      "          1.8096e-02,  7.4900e-02, -7.1105e-02,  4.4946e-02,  2.0573e-02,\n",
      "          1.0170e-01,  6.0430e-02,  4.1812e-02,  2.1518e-02, -4.0442e-02,\n",
      "          3.4351e-02, -8.5656e-03, -6.8284e-02, -2.0304e-02,  9.0532e-02,\n",
      "          5.8589e-03,  8.0122e-02,  8.6059e-02, -6.8273e-02,  3.6525e-02,\n",
      "          5.5661e-02, -1.0565e-01, -2.3669e-02, -9.6977e-02,  1.0274e-01,\n",
      "          8.1225e-02,  1.4682e-02, -9.1092e-02, -8.8799e-02, -8.6815e-02,\n",
      "          1.0260e-01, -5.4900e-02,  7.9783e-02, -6.3416e-02,  5.3055e-02,\n",
      "          5.1361e-02, -8.0411e-02, -1.2843e-02,  1.1516e-02,  3.9941e-02,\n",
      "         -1.9526e-02,  6.0336e-02,  9.6294e-03,  7.9741e-02, -1.0184e-01,\n",
      "          4.8552e-02, -8.0429e-02, -8.4175e-03,  5.0660e-02, -2.3318e-02,\n",
      "         -8.8789e-02,  3.6424e-02,  8.4705e-02, -5.8932e-02, -3.1246e-02,\n",
      "          5.5818e-02,  7.9101e-02, -2.0225e-02, -9.6297e-02,  1.0286e-01,\n",
      "         -6.3815e-02, -5.0312e-02,  1.0361e-03, -8.2075e-03, -6.5736e-02,\n",
      "          1.6755e-02, -1.0955e-01, -9.5289e-02, -3.1664e-03, -6.4511e-02,\n",
      "         -8.0010e-02,  3.6783e-02,  4.9724e-02,  4.6543e-02]], device='cuda:0'), 'classifier.4.bias': tensor([-0.0452,  0.0334, -0.0350, -0.0985,  0.0188,  0.0319,  0.0144,  0.0136,\n",
      "        -0.0236, -0.1054], device='cuda:0')})\n"
     ]
    }
   ],
   "source": [
    "def generated_feature():\n",
    "    folder_model = \"D:\\\\2025\\\\Projects\\\\self_supervisedlearning\\\\lstm\\\\model_save\\\\LeNet_with_5classes\\\\\"\n",
    "    file_list = [f for f in os.listdir(folder_model) if f.endswith(\".pth\")]\n",
    "    \n",
    "    print(f\"Found .pth files: {file_list}\")\n",
    "    \n",
    "    if not file_list:\n",
    "        print(\"No .pth files found!\")\n",
    "        return\n",
    "    \n",
    "    path = f\"LeNet_cifar10_{0}.pth\"\n",
    "    model_data = torch.load(os.path.join(folder_model, path), map_location=device)\n",
    "    print(f\"Loaded model type: {type(model_data)}\")\n",
    "    print(model_data)\n",
    "    return model_data\n",
    "\n",
    "model_with5classes = generated_feature()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_selected = [0,1,2,3,4,5]\n",
    "data6classes, _ = data_semi_learning(data_use=data_use, num_class=num_classes, batch_size=64, labeled_classes=label_selected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pseudo Label\n",
    "1. Check with cluster algorithsm\n",
    "- DBSCAN\n",
    "- Affinity Propagation\n",
    "-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "luan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
